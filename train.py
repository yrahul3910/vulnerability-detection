import pickle
import numpy as np
import sys
from sklearn.model_selection import train_test_split
from raise_utils.transform import Transform
from raise_utils.data import Data
from raise_utils.learners import FeedforwardDL, Autoencoder


# Configurations for each stage of GHOST-v2.
process_configs = {
    'base': {
        'weighted_loss': False,
        'wfo': False,
        'dodge': True,
        'smote': False,
        'ultrasample': False
    },
    'weighted': {
        'weighted_loss': True,
        'smote': True,
        'wfo': False,
        'dodge': True,
        'ultrasample': False
    },
    'wfo': {
        'weighted_loss': True,
        'smote': True,
        'dodge': True,
        'wfo': True,
        'ultrasample': False
    },
    'ghost': {
        'weighted_loss': True,
        'wfo': True,
        'dodge': True,
        'smote': True,
        'ultrasample': True
    }
}



if __name__ == '__main__':
    if len(sys.argv) != 3:
        print('Usage: train.py DATASET TREATMENT')
        sys.exit(1)

    dataset = sys.argv[1]
	treatment = sys.argv[2]

	if treatment not in process_configs.keys():
		print('treatment must be one of', list(process_configs.keys()))
		sys.exit(2)

    with open(f'./data/final/{dataset}.pickle', 'rb') as f:
        data = pickle.load(f)

    X = data['X']
    y = data['y'].ravel()

    data = Data(*train_test_split(X, y))

    # Ultrasampling
	if process_configs[treatment]['ultrasample']:
		transform = Transform('wfo')
		transform.apply(data)

		data.y_train = 1. - data.y_train
		data.y_test = 1. - data.y_test

		# Autoencode the inputs
		loss = 1e4
		while loss > 1e2:
			ae = Autoencoder(n_layers=3, n_units=[128, 64, 32], n_out=16)
			ae.set_data(*data)
			ae.fit()

			loss = ae.model.history.history['loss'][-1]

		data.x_train = ae.encode(np.array(data.x_train))
		data.x_test = ae.encode(np.array(data.x_test))

    # Tune the hyper-params
    dodge_config = {
        'n_runs': 10,
        'data': [data],
        'metrics': ['d2h', 'f1', 'pd', 'pf', 'prec'],
        'learners': [],
        'log_path': './log/',
        'transforms': ['standardize', 'normalize', 'minmax'] * 30,
        'random': True,
        'name': f'{dataset}-{treatment}'
    }

    for _ in range(30):
		weighted = process_configs[treatment]['weighted']
		wfo = process_configs[treatment]['wfo']
		smote = process_configs[treatment]['smote']

        dodge_config['learners'].append(
            FeedforwardDL(weighted=weighted, wfo=wfo, smote=smote,
                          random={'n_units': (
                              2, 18), 'n_layers': (2, 5)},
                          n_epochs=100)
        )

    dodge = DODGE(dodge_config)
    dodge.optimize()
