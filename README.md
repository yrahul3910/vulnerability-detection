# Vulnerability Detection

## Data

This directory contains the datasets used. The `raw/` directory contains the raw data from the Devign paper. The authors released the qemu and ffmpeg datasets.

## Getting Started

### Step 1: Separate JSON to datasets

The raw data is processed by `preprocess.py`, which writes to `processed/`. This creates a structure like this:

```
data/
    processed/
        ffmpeg/
            1.cpp
            2.cpp
            ...
            labels.csv
        qemu/
            1.cpp
            2.cpp
            ...
            labels.csv
    raw/
        dataset.json
```

The cpp files contain the code, which will be processed by [`astminer`](https://github.com/JetBrains-Research/astminer), which converts them to sequences. The CSV files contain `file` and `target` columns.

### Step 2: Converting to code2vec format

Now, clone the [`astminer`](https://github.com/JetBrains-Research/astminer) repo

```
git clone https://github.com/JetBrains-Research/astminer.git
```

Then, run `code2vec.sh`. This will likely need a machine with a lot of memory.

Next, clone the `code2vec` repo:

```
git clone https://github.com/tech-srl/code2vec.git
```

Then, split this data into train/test/validation splits for code2vec:

```
python3 split.py
```

This will write three files, `dataset.{train,test,val}.txt` in `./data/preprocessed/{qemu,ffmpeg}`.

### Step 3: Train code2vec models

Now, preprocess the data:

```
cd code2vec/
cp ../code2vec_preprocess.sh ./preprocess.sh
./preprocess.sh
```

Next, update the `train.sh` file in the `code2vec/` directory. Only one line needs updating, that is:

```
data_dir=./data
```

The above is the updated version. Finally, run `./train.sh` to train the `code2vec` models. We move the final code2vec data to `data/code2vec`, and the models to `models/`.

### Step 4: Prepare data for test

To run our approach, we need to prepare the data in essentially the same way as above, but keeping track of the labels. We do this in a batched manner, to also reduce the computational load. First, run `prep_test.py`. This creates batches in a directory called `test/`. So the directory structure should look like:

```
data/
    test/
        ffmpeg/
            00/
            01/
            ...
        qemu/
            00/
            01/
            ...
```

Now, we process the batches by running `process_batches.sh`. We do this in batches of 1, and combine them in the next step. The individual files are compressed and stored in `data/code2vec/{qemu|ffmpeg}.tar.gz`. We then preprocess these files by running `preprocess_test.sh`.

### Step 5: Finalize the test set

Finally, run `generate_vectors.sh` to create code vectors files, which contains the code2vec vectors in sequential order:

```
./generate_vectors.sh ffmpeg
./generate_vectors.sh qemu
```

Then, run `generate_dataset.py` to generate a `.pickle` file in the `data/code2vec/` directory.

### Step 6: Train the models

Finally, run the `train.py` file. An example (using slurm) is shown in `run.sh`.

```
python3 train.py {qemu|ffmpeg} {base|weighted|wfo|ghost}
```
