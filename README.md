# Vulnerability Detection

## Data

This directory contains the datasets used. The `raw/` directory contains the raw data from the Devign paper. The authors released the qemu and ffmpeg datasets.

## Preprocessing

### Step 1: Separate JSON to datasets

The raw data is processed by `preprocess.py`, which writes to `processed/`. This creates a structure like this:

```
data/
    processed/
        ffmpeg/
            1.cpp
            2.cpp
            ...
            labels.csv
        qemu/
            1.cpp
            2.cpp
            ...
            labels.csv
    raw/
        dataset.json
```

The cpp files contain the code, which will be processed by [`astminer`](https://github.com/JetBrains-Research/astminer), which converts them to sequences. The CSV files contain `file` and `target` columns.

### Step 2: Converting to code2vec format

Now, clone the [`astminer`](https://github.com/JetBrains-Research/astminer) repo

```
git clone https://github.com/JetBrains-Research/astminer.git
```

Then, run `code2vec.sh`. This will likely need a machine with a lot of memory. 

Next, clone the `code2vec` repo:

```
git clone https://github.com/tech-srl/code2vec.git
```

Then, split this data into train/test/validation splits for code2vec:

```
python3 split.py
```

This will write three files, `dataset.{train,test,val}.txt` in `./data/preprocessed/{qemu,ffmpeg}`. 

### Step 3: Train code2vec models

Now, preprocess the data:

```
cd code2vec/
cp ../code2vec_preprocess.sh ./preprocess.sh
./preprocess.sh
```

Next, update the `train.sh` file in the `code2vec/` directory. Only one line needs updating, that is:

```
data_dir=./data
```

The above is the updated version. Finally, run `./train.sh` to train the `code2vec` models. We move the final code2vec data to `data/code2vec`, and the models to `models/`.

### Step 4: Prepare data for test

To run our approach, we need to prepare the data in essentially the same way as above, but keeping track of the labels. We do this in a batched manner, to also reduce the computational load. First, run `prep_test.py`. This creates batches in a directory called `test/`. So the directory structure should look like:

```
data/
    test/
        ffmpeg/
            00/
            01/
            ...
        qemu/
            00/
            01/
            ...
```

Now, we process the batches by running `process_batches.sh`.
